{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from tools.utils import manual_seed\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tools.img import rgb2yuv, yuv2rgb, rgb_to_yuv, yuv_to_rgb\n",
    "from torchvision.transforms.transforms import ToTensor\n",
    "from tools.dataset import get_dataloader, get_dataset_class_and_scale, get_dataset_normalization, get_de_normalization\n",
    "from omegaconf import OmegaConf\n",
    "from tools.img import tensor2ndarray, ndarray2tensor\n",
    "from torchmetrics import StructuralSimilarityIndexMeasure\n",
    "from tools.dataset import get_dataloader\n",
    "# from tools.inject_backdoor import patch_trigger\n",
    "\n",
    "manual_seed(42)\n",
    "loss = StructuralSimilarityIndexMeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = '../' + 'results/imagenette/inba/20241018041919_ab4_best'\n",
    "path = f'{target_folder}/config.yaml'\n",
    "config = OmegaConf.load(path)\n",
    "manual_seed(config.seed)\n",
    "\n",
    "device = f'cuda:{config.device}'\n",
    "num_class, scale = get_dataset_class_and_scale(config.dataset_name)\n",
    "if config.model == \"resnet18\":\n",
    "    from models.preact_resnet import PreActResNet18\n",
    "    net = PreActResNet18(num_classes=num_class).to(f'cuda:{config.device}')\n",
    "elif config.model == \"rnp\":\n",
    "    from models.resnet_cifar import resnet18\n",
    "    net = resnet18(num_classes=num_class).to(f'cuda:{config.device}')\n",
    "elif config.model == \"repvgg\":\n",
    "    from repvgg_pytorch.repvgg import RepVGG\n",
    "    net = RepVGG(num_blocks=[2, 4, 14, 1], num_classes=num_class, width_multiplier=[1.5, 1.5, 1.5, 2.75]).to(device=f'cuda:{config.device}')\n",
    "else:\n",
    "    raise NotImplementedError(config.model)\n",
    "ld = torch.load(f'{target_folder}/results.pth', map_location=device)\n",
    "net.load_state_dict(ld['model'])\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a example image and plot RGB channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the RGB image to YUV channels, and plot them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use INBA to add pertubation to the imaginary part of U channel after FFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, dl = get_dataloader(config.dataset_name, config.batch, config.pin_memory, config.num_workers)\n",
    "x_c = None\n",
    "for batch, label in dl:\n",
    "    for i in range(batch.shape[0]):\n",
    "        if label[i] == 1:\n",
    "            x_c = batch[i]\n",
    "            break\n",
    "    if x_c != None:\n",
    "        break\n",
    "\n",
    "sys.path.append('./run')\n",
    "sys.path.append(target_folder)\n",
    "from inject_backdoor import patch_trigger\n",
    "x_p = patch_trigger(x_c, config)\n",
    "\n",
    "x_c = x_c.to(device)\n",
    "x_p = x_p.to(device)\n",
    "x_c = get_de_normalization(config.dataset_name)(x_c).squeeze()\n",
    "x_p = get_de_normalization(config.dataset_name)(x_p).squeeze()\n",
    "x_p = torch.clip(x_p, 0, 1)\n",
    "\n",
    "x_c = get_dataset_normalization(config.dataset_name)(x_c)\n",
    "x_p = get_dataset_normalization(config.dataset_name)(x_p)\n",
    "\n",
    "if config.model == 'repvgg':\n",
    "    net.deploy = True\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    out_c = net(x_c.unsqueeze(0))\n",
    "    out_p = net(x_p.unsqueeze(0))\n",
    "    _, y_c = torch.max(out_c, 1)\n",
    "    _, y_p = torch.max(out_p, 1)\n",
    "\n",
    "print(y_c.item())\n",
    "print(y_p.item())\n",
    "\n",
    "print(x_c[0, 0:3, 0:3])\n",
    "print(x_p[0, 0:3, 0:3])\n",
    "\n",
    "x_c = get_de_normalization(config.dataset_name)(x_c).squeeze()\n",
    "x_p = get_de_normalization(config.dataset_name)(x_p).squeeze()\n",
    "\n",
    "_, ax = plt.subplots(1, 2, figsize=(15, 10))\n",
    "ax[0].imshow(tensor2ndarray(x_c))\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(tensor2ndarray(x_p))\n",
    "ax[1].axis('off')\n",
    "plt.show()\n",
    "ssim_metric = loss(data_range=1.0).to(device)(x_c.unsqueeze(0), x_p.unsqueeze(0))\n",
    "print(f'ssim: {ssim_metric}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diffusion-Backdoor-Embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
